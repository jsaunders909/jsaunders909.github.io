---
layout: about
title: about
permalink: /
description: PhD Candidate, University of Bath

profile:
  align: right
  image: me_2024.jpg
  address: >
    <p>1W 4.20</p>
    <p>University of Bath, Claverton Down </p>
    <p>Bath BA2 7AY</p>

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hi! I'm Jack, a reasearch scientist working on AI Avatars. I have recently finished my PhD and was fortunate to be supervised by [Vinay Namboodiri](https://vinaypn.github.io/) and [Darren Cosker](https://www.cs.bath.ac.uk/~dpc/). I'm a part of [ART-AI](https://cdt-art-ai.ac.uk/) and [CAMERA](https://www.camera.ac.uk/). I run [RealSyncAI](http://realsyncai.com/) where I work with companies to build the next generation of Avatars, lip-sync models, and video dubbing. I'm spending most of my time these days building the rendering technology being used by [Tavus](https://tavus.io/). I have also interned with Microsoft and Epic Games.

My research is centred around deep learning for Digital Humans. In particular, I'm looking at *style* in 2D and 3D facial animation, in particular emotional and idiosyncratic. The ultimate aim of my research is to allow for the creation and editing of facial video and 3D animations without the need for artistic skill or expensive performance capture systems. I'm also trying to keep it with the latest tech including: Gaussian Splatting, Diffusion Models, Transformers and Inverse/Differentiable Rendering.
